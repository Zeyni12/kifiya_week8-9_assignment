{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier \n",
    "from sklearn.metrics import classification_report \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import mlflow.tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_credit = pd.read_csv('../data/credit_card.csv')\n",
    "df_credit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    284315\n",
       "1       492\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_credit['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Splitting the data into Features and Targets\n",
    "X = df_credit.drop(columns='Class',  axis=1)\n",
    "Y = df_credit['Class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Split the data into Traning data and Testing Data\n",
    "\n",
    "#X_train, X_test, Y_train,Y_test = train_test_split(X,Y, test_size=0.2, stratify=Y, random_state=2)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.83      0.70      0.76        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.92      0.85      0.88     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the model parameters \n",
    "params = {\n",
    "    'solver': 'lbfgs',\n",
    "    'max_iter': 1000,\n",
    "    'multi_class': 'auto',\n",
    "    'random_state': 8888,\n",
    "}\n",
    "\n",
    "#Train the model \n",
    "lr = LogisticRegression(**params)\n",
    "lr.fit(X_train, Y_train)\n",
    "\n",
    "#predict on the test set \n",
    "Y_pred = lr.predict(X_test)\n",
    "\n",
    "report = classification_report(Y_test,Y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.9994901457479913,\n",
       "  'recall': 0.9997537985368599,\n",
       "  'f1-score': 0.9996219547576554,\n",
       "  'support': 56864.0},\n",
       " '1': {'precision': 0.8313253012048193,\n",
       "  'recall': 0.7040816326530612,\n",
       "  'f1-score': 0.7624309392265194,\n",
       "  'support': 98.0},\n",
       " 'accuracy': 0.9992451107756047,\n",
       " 'macro avg': {'precision': 0.9154077234764053,\n",
       "  'recall': 0.8519177155949605,\n",
       "  'f1-score': 0.8810264469920874,\n",
       "  'support': 56962.0},\n",
       " 'weighted avg': {'precision': 0.9992008273468602,\n",
       "  'recall': 0.9992451107756047,\n",
       "  'f1-score': 0.9992138806113464,\n",
       "  'support': 56962.0}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_dict = classification_report(Y_test, Y_pred, output_dict=True)\n",
    "report_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"Test Experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/14 11:37:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run adaptable-colt-287 at: http://127.0.0.1:5000/#/experiments/688471250164079586/runs/164c0c5532574c67b418477c4e6785cc\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/688471250164079586\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metrics({\n",
    "        'accuracy': report_dict['accuracy'],\n",
    "        'recall_class_0': report_dict['0']['recall'],\n",
    "        'recall_class_1': report_dict['1']['recall'],\n",
    "        'f1_score_macro':report_dict['macro avg']['f1-score']\n",
    "    })\n",
    "    mlflow.sklearn.log_model(lr, 'Logistic Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 1: Train Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.73      0.67      0.70        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.86      0.84      0.85     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(C=1, solver='liblinear')\n",
    "log_reg.fit(X_train,Y_train)\n",
    "Y_pred_log_reg = log_reg.predict(X_test)\n",
    "print(classification_report(Y_test,Y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 2: Train Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.73      0.67      0.70        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.86      0.84      0.85     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=30, max_depth=3)\n",
    "rf_clf.fit(X_train,Y_train)\n",
    "Y_pred_rf = rf_clf.predict(X_test)\n",
    "print(classification_report(Y_test,Y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 3: Train XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.73      0.67      0.70        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.86      0.84      0.85     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(use_lable_encoder=False, eval_metric='logloss')\n",
    "xgb_clf.fit(X_train,Y_train)\n",
    "Y_pred_xgb = xgb_clf.predict(X_test)\n",
    "print(classification_report(Y_test,Y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 4: Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.88      0.78      0.83        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.94      0.89      0.91     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(max_depth=5)  # You can tune hyperparameters\n",
    "dt_clf.fit(X_train, Y_train)\n",
    "Y_pred_dt = dt_clf.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test, Y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Track ML models Experiments Using MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\n",
    "        'Logistic Regression',\n",
    "        LogisticRegression(C=1, solver='liblinear'),\n",
    "        (X_train,Y_train),\n",
    "        (X_test,Y_test)\n",
    "\n",
    "    ),\n",
    "    (\n",
    "        'Random Forest',\n",
    "        RandomForestClassifier(n_estimators=30, max_depth=3),\n",
    "        (X_train,Y_train),\n",
    "        (X_test,Y_test)\n",
    "    ),\n",
    "    (\n",
    "         'XGBClassifier',\n",
    "          XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "          (X_train,Y_train),\n",
    "          (X_test,Y_test)\n",
    "    ),\n",
    "    (\n",
    "        'Decision Tree',\n",
    "         DecisionTreeClassifier(max_depth=5),\n",
    "        (X_train,Y_train),\n",
    "        (X_test,Y_test)\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = []\n",
    "\n",
    "for model_name, model, train_set, test_set in models:\n",
    "    X_train = train_set[0]\n",
    "    Y_train = train_set[1]\n",
    "    X_test = test_set[0]\n",
    "    Y_test = test_set[1]\n",
    "\n",
    "    model.fit(X_train, Y_train)\n",
    "    Y_pred = model.predict(X_test)\n",
    "    report = classification_report(Y_test, Y_pred,output_dict=True)\n",
    "    reports.append(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/14 16:53:48 INFO mlflow.tracking.fluent: Experiment with name 'model tranning for credit_data' does not exist. Creating a new experiment.\n",
      "2025/02/14 16:53:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run Logistic Regression at: http://127.0.0.1:5000/#/experiments/254128385064261023/runs/bc43364bd36346e0a7d6307e9367dd5e\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/254128385064261023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/14 16:54:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run Random Forest at: http://127.0.0.1:5000/#/experiments/254128385064261023/runs/f4d1a970c60141ccbdb6455bf97b55bd\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/254128385064261023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/14 16:54:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run XGBClassifier at: http://127.0.0.1:5000/#/experiments/254128385064261023/runs/85a3497f9a0a4896b250e4bcf48efa8b\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/254128385064261023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/14 16:54:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run Decision Tree at: http://127.0.0.1:5000/#/experiments/254128385064261023/runs/88b6c321cec242a3840c2e30d91d2cd2\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/254128385064261023\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment('model tranning for credit_data')\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")\n",
    "\n",
    "for i, element in enumerate(models):\n",
    "    model_name = element[0]\n",
    "    model = element[1]\n",
    "    report = reports[i]\n",
    "\n",
    "    with mlflow.start_run(run_name = model_name):\n",
    "        mlflow.log_param('model_name', model_name)\n",
    "        mlflow.log_metric('accuracy', report['accuracy'])\n",
    "        mlflow.log_metric('recall_class_1', report['1']['recall'])\n",
    "        mlflow.log_metric('recall_class_0', report['0']['recall'])\n",
    "        mlflow.log_metric('f1_score_macro', report['macro avg']['f1-score'])\n",
    "\n",
    "        if 'XGB' in model_name:\n",
    "            mlflow.xgboost.log_model(model, 'model')\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(model, 'model')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Deep learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 1:Multi-Layer Perceptron (MLP) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.43      0.81      0.56        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.71      0.90      0.78     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)\n",
    "mlp_clf.fit(X_train, Y_train)\n",
    "Y_pred_mlp = mlp_clf.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test, Y_pred_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 2 : Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 4ms/step - accuracy: 0.9941 - loss: 4.6451\n",
      "Epoch 2/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - accuracy: 0.9986 - loss: 0.1519\n",
      "Epoch 3/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0184\n",
      "Epoch 4/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - accuracy: 0.9992 - loss: 0.0090\n",
      "Epoch 5/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0079\n",
      "Epoch 6/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5ms/step - accuracy: 0.9992 - loss: 0.0059\n",
      "Epoch 7/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - accuracy: 0.9992 - loss: 0.0063\n",
      "Epoch 8/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 0.0062\n",
      "Epoch 9/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 0.0110\n",
      "Epoch 10/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5ms/step - accuracy: 0.9994 - loss: 0.0035\n",
      "\u001b[1m1781/1781\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.85      0.79      0.81        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.92      0.89      0.91     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "# Convert DataFrame to NumPy array\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "# Reshape input for CNN\n",
    "X_train_cnn = X_train.reshape(-1, X_train.shape[1], 1)\n",
    "X_test_cnn = X_test.reshape(-1, X_test.shape[1], 1)\n",
    "\n",
    "# Check if it's binary or multi-class\n",
    "num_classes = len(np.unique(Y_train))\n",
    "\n",
    "if num_classes == 2:\n",
    "    # Binary classification (0/1)\n",
    "    Y_train_cnn = np.array(Y_train)\n",
    "    Y_test_cnn = np.array(Y_test)\n",
    "    loss_function = \"binary_crossentropy\"\n",
    "    final_activation = \"sigmoid\"\n",
    "    output_units = 1\n",
    "else:\n",
    "    # Multi-class classification\n",
    "    Y_train_cnn = to_categorical(Y_train, num_classes)\n",
    "    Y_test_cnn = to_categorical(Y_test, num_classes)\n",
    "    loss_function = \"categorical_crossentropy\"\n",
    "    final_activation = \"softmax\"\n",
    "    output_units = num_classes\n",
    "\n",
    "# Define CNN model\n",
    "cnn_model = models.Sequential([\n",
    "    layers.Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(50, activation='relu'),\n",
    "    layers.Dense(output_units, activation=final_activation)  # Adjust for binary/multi-class\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss=loss_function, metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "cnn_model.fit(X_train_cnn, Y_train_cnn, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "# Predictions\n",
    "Y_pred_cnn = cnn_model.predict(X_test_cnn)\n",
    "Y_pred_cnn_classes = (Y_pred_cnn > 0.5).astype(int) if num_classes == 2 else Y_pred_cnn.argmax(axis=1)\n",
    "\n",
    "print(classification_report(Y_test, Y_pred_cnn_classes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 7:Recurrent Neural Network (RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 8ms/step - accuracy: 0.9982 - loss: 0.1085\n",
      "Epoch 2/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9ms/step - accuracy: 0.9981 - loss: 0.0223\n",
      "Epoch 3/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 8ms/step - accuracy: 0.9985 - loss: 0.0089\n",
      "Epoch 4/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 9ms/step - accuracy: 0.9985 - loss: 0.0079\n",
      "Epoch 5/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 9ms/step - accuracy: 0.9986 - loss: 0.0078\n",
      "Epoch 6/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 9ms/step - accuracy: 0.9989 - loss: 0.0068\n",
      "Epoch 7/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 9ms/step - accuracy: 0.9990 - loss: 0.0059\n",
      "Epoch 8/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0056\n",
      "Epoch 9/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 9ms/step - accuracy: 0.9987 - loss: 0.0075\n",
      "Epoch 10/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0060\n",
      "\u001b[1m1781/1781\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.81      0.80      0.80        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.91      0.90      0.90     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import SimpleRNN\n",
    "\n",
    "rnn_model = models.Sequential([\n",
    "    SimpleRNN(50, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    layers.Dense(50, activation='relu'),\n",
    "    layers.Dense(output_units, activation=final_activation)  # Adjusted for binary/multi-class\n",
    "])\n",
    "\n",
    "rnn_model.compile(optimizer='adam', loss=loss_function, metrics=['accuracy'])\n",
    "\n",
    "rnn_model.fit(X_train, Y_train, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "Y_pred_rnn = rnn_model.predict(X_test)\n",
    "Y_pred_rnn_classes = (Y_pred_rnn > 0.5).astype(int) if num_classes == 2 else Y_pred_rnn.argmax(axis=1)\n",
    "\n",
    "print(classification_report(Y_test, Y_pred_rnn_classes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 8:Long Short-Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 16ms/step - accuracy: 0.9621 - loss: 41.4880\n",
      "Epoch 2/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 17ms/step - accuracy: 0.9951 - loss: 2.9446\n",
      "Epoch 3/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 18ms/step - accuracy: 0.9974 - loss: 0.4701\n",
      "Epoch 4/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 17ms/step - accuracy: 0.9966 - loss: 1.0812\n",
      "Epoch 5/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 18ms/step - accuracy: 0.9962 - loss: 4.7240\n",
      "Epoch 6/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 17ms/step - accuracy: 0.9961 - loss: 3.3617\n",
      "Epoch 7/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 10ms/step - accuracy: 0.9966 - loss: 43.8264\n",
      "Epoch 8/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 11ms/step - accuracy: 0.9968 - loss: 6.9366\n",
      "Epoch 9/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 12ms/step - accuracy: 0.9967 - loss: 4.3280\n",
      "Epoch 10/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 11ms/step - accuracy: 0.9965 - loss: 8.4695\n",
      "\u001b[1m1781/1781\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.00      0.00      0.00        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.50      0.50      0.50     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "lstm_model = models.Sequential([\n",
    "    LSTM(50, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    layers.Dense(50, activation='relu'),\n",
    "    layers.Dense(output_units, activation=final_activation)  # Adjusted for binary/multi-class\n",
    "])\n",
    "\n",
    "lstm_model.compile(optimizer='adam', loss=loss_function, metrics=['accuracy'])\n",
    "\n",
    "lstm_model.fit(X_train_cnn, Y_train_cnn, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "Y_pred_lstm = lstm_model.predict(X_test_cnn)\n",
    "Y_pred_lstm_classes = (Y_pred_lstm > 0.5).astype(int) if num_classes == 2 else Y_pred_lstm.argmax(axis=1)\n",
    "\n",
    "print(classification_report(Y_test, Y_pred_lstm_classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Track Deep learning models Experiments Using MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_learning_models = {\n",
    "    \"CNN\": models.Sequential([\n",
    "        layers.Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(50, activation='relu'),\n",
    "        layers.Dense(output_units, activation=final_activation)\n",
    "    ]),\n",
    "    \"RNN\": models.Sequential([\n",
    "        layers.SimpleRNN(50, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "        layers.Dense(50, activation='relu'),\n",
    "        layers.Dense(output_units, activation=final_activation)\n",
    "    ]),\n",
    "    \"LSTM\": models.Sequential([\n",
    "        layers.LSTM(50, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "        layers.Dense(50, activation='relu'),\n",
    "        layers.Dense(output_units, activation=final_activation)\n",
    "    ])\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment('Deepmodel tranning for credit_data')\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - accuracy: 0.9932 - loss: 10.0789\n",
      "Epoch 2/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.1342\n",
      "Epoch 3/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0194\n",
      "Epoch 4/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0132\n",
      "Epoch 5/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0210\n",
      "Epoch 6/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0088\n",
      "Epoch 7/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0064\n",
      "Epoch 8/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0080\n",
      "Epoch 9/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0042\n",
      "Epoch 10/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0066\n",
      "\u001b[1m1781/1781\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/16 11:30:03 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "2025/02/16 11:30:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged CNN successfully in MLflow\n",
      "ðŸƒ View run CNN at: http://127.0.0.1:5000/#/experiments/254128385064261023/runs/25a0c5004d48476cae34e02e362d6c8e\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/254128385064261023\n",
      "Epoch 1/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 6ms/step - accuracy: 0.9862 - loss: 0.3647\n",
      "Epoch 2/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 6ms/step - accuracy: 0.9982 - loss: 0.0252\n",
      "Epoch 3/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 6ms/step - accuracy: 0.9984 - loss: 0.0105\n",
      "Epoch 4/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 6ms/step - accuracy: 0.9984 - loss: 0.0164\n",
      "Epoch 5/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 6ms/step - accuracy: 0.9988 - loss: 0.0076\n",
      "Epoch 6/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 6ms/step - accuracy: 0.9989 - loss: 0.0064\n",
      "Epoch 7/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 6ms/step - accuracy: 0.9981 - loss: 0.0134\n",
      "Epoch 8/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 6ms/step - accuracy: 0.9990 - loss: 0.0059\n",
      "Epoch 9/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 6ms/step - accuracy: 0.9989 - loss: 0.0073\n",
      "Epoch 10/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 6ms/step - accuracy: 0.9987 - loss: 0.0086\n",
      "\u001b[1m1781/1781\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/16 11:38:05 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "2025/02/16 11:38:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged RNN successfully in MLflow\n",
      "ðŸƒ View run RNN at: http://127.0.0.1:5000/#/experiments/254128385064261023/runs/c8fd54ceabaa4245ae7203f8e7dad8ab\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/254128385064261023\n",
      "Epoch 1/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 12ms/step - accuracy: 0.9934 - loss: 3.3666\n",
      "Epoch 2/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 11ms/step - accuracy: 0.9949 - loss: 7.4585\n",
      "Epoch 3/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 11ms/step - accuracy: 0.9969 - loss: 8.3021\n",
      "Epoch 4/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 11ms/step - accuracy: 0.9967 - loss: 4.3408\n",
      "Epoch 5/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 12ms/step - accuracy: 0.9968 - loss: 8.7278\n",
      "Epoch 6/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 12ms/step - accuracy: 0.9961 - loss: 4.6730\n",
      "Epoch 7/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 12ms/step - accuracy: 0.9931 - loss: 68.6101\n",
      "Epoch 8/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 12ms/step - accuracy: 0.9964 - loss: 2.1685\n",
      "Epoch 9/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 11ms/step - accuracy: 0.9980 - loss: 0.5652\n",
      "Epoch 10/10\n",
      "\u001b[1m7121/7121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 12ms/step - accuracy: 0.9973 - loss: 0.1428\n",
      "\u001b[1m1781/1781\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/16 11:53:01 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "2025/02/16 11:53:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged LSTM successfully in MLflow\n",
      "ðŸƒ View run LSTM at: http://127.0.0.1:5000/#/experiments/254128385064261023/runs/ed478e9b83c3455f882c47c691233d4b\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/254128385064261023\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in deep_learning_models.items():\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Compile and Train\n",
    "        model.compile(optimizer='adam', loss=loss_function, metrics=['accuracy'])\n",
    "        model.fit(X_train_cnn, Y_train_cnn, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "        # Make predictions\n",
    "        Y_pred = model.predict(X_test_cnn)\n",
    "        Y_pred_classes = (Y_pred > 0.5).astype(int) if num_classes == 2 else Y_pred.argmax(axis=1)\n",
    "\n",
    "        # Compute classification metrics\n",
    "        report = classification_report(Y_test, Y_pred_classes, output_dict=True)\n",
    "\n",
    "        # Log metrics\n",
    "        mlflow.log_metrics({\n",
    "            'accuracy': report['accuracy'],\n",
    "            'recall_class_0': report['0']['recall'],\n",
    "            'recall_class_1': report['1']['recall'],\n",
    "            'f1_score_macro': report['macro avg']['f1-score']\n",
    "        })\n",
    "\n",
    "        # Log deep learning model\n",
    "        mlflow.tensorflow.log_model(model, model_name)\n",
    "\n",
    "        print(f\"Logged {model_name} successfully in MLflow\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
