{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier \n",
    "from sklearn.metrics import classification_report \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import mlflow.tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>signup_time</th>\n",
       "      <th>purchase_time</th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>device_id</th>\n",
       "      <th>source</th>\n",
       "      <th>browser</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>class</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>247547</td>\n",
       "      <td>2015-06-28 03:00:34</td>\n",
       "      <td>2015-08-09 03:57:29</td>\n",
       "      <td>47</td>\n",
       "      <td>KIXYSVCHIPQBR</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Safari</td>\n",
       "      <td>F</td>\n",
       "      <td>30</td>\n",
       "      <td>16778864</td>\n",
       "      <td>0</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220737</td>\n",
       "      <td>2015-01-28 14:21:11</td>\n",
       "      <td>2015-02-11 20:28:28</td>\n",
       "      <td>15</td>\n",
       "      <td>PKYOWQKWGJNJI</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>F</td>\n",
       "      <td>34</td>\n",
       "      <td>16842045</td>\n",
       "      <td>0</td>\n",
       "      <td>Thailand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>390400</td>\n",
       "      <td>2015-03-19 20:49:09</td>\n",
       "      <td>2015-04-11 23:41:23</td>\n",
       "      <td>44</td>\n",
       "      <td>LVCSXLISZHVUO</td>\n",
       "      <td>Ads</td>\n",
       "      <td>IE</td>\n",
       "      <td>M</td>\n",
       "      <td>29</td>\n",
       "      <td>16843656</td>\n",
       "      <td>0</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69592</td>\n",
       "      <td>2015-02-24 06:11:57</td>\n",
       "      <td>2015-05-23 16:40:14</td>\n",
       "      <td>55</td>\n",
       "      <td>UHAUHNXXUADJE</td>\n",
       "      <td>Direct</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>F</td>\n",
       "      <td>30</td>\n",
       "      <td>16938732</td>\n",
       "      <td>0</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>174987</td>\n",
       "      <td>2015-07-07 12:58:11</td>\n",
       "      <td>2015-11-03 04:04:30</td>\n",
       "      <td>51</td>\n",
       "      <td>XPGPMOHIDRMGE</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>F</td>\n",
       "      <td>37</td>\n",
       "      <td>16971984</td>\n",
       "      <td>0</td>\n",
       "      <td>Thailand</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id          signup_time        purchase_time  purchase_value  \\\n",
       "0   247547  2015-06-28 03:00:34  2015-08-09 03:57:29              47   \n",
       "1   220737  2015-01-28 14:21:11  2015-02-11 20:28:28              15   \n",
       "2   390400  2015-03-19 20:49:09  2015-04-11 23:41:23              44   \n",
       "3    69592  2015-02-24 06:11:57  2015-05-23 16:40:14              55   \n",
       "4   174987  2015-07-07 12:58:11  2015-11-03 04:04:30              51   \n",
       "\n",
       "       device_id  source browser sex  age  ip_address  class    country  \n",
       "0  KIXYSVCHIPQBR     SEO  Safari   F   30    16778864      0  Australia  \n",
       "1  PKYOWQKWGJNJI     SEO  Chrome   F   34    16842045      0   Thailand  \n",
       "2  LVCSXLISZHVUO     Ads      IE   M   29    16843656      0      China  \n",
       "3  UHAUHNXXUADJE  Direct  Chrome   F   30    16938732      0      China  \n",
       "4  XPGPMOHIDRMGE     SEO  Chrome   F   37    16971984      0   Thailand  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fraud = pd.read_csv('../data/Merged_Fraud_Data.csv')\n",
    "df_fraud.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    116878\n",
       "1     12268\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fraud['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   purchase_value       age\n",
      "0        0.549607 -0.363124\n",
      "1       -1.197335  0.101168\n",
      "2        0.385831 -0.479197\n",
      "3        0.986342 -0.363124\n",
      "4        0.767974  0.449387\n"
     ]
    }
   ],
   "source": [
    "##Normalize & Scale Numerical Features\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Select numerical features for scaling\n",
    "num_features = [\"purchase_value\",'age']\n",
    "\n",
    "# Apply StandardScaler (mean = 0, std = 1)\n",
    "scaler = StandardScaler()\n",
    "df_fraud[num_features] = scaler.fit_transform(df_fraud[num_features])\n",
    "\n",
    "# Display scaled values\n",
    "print(df_fraud[num_features].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# Features to One-Hot Encode (only low-cardinality ones)\n",
    "low_cardinality_features = [\"source\", \"sex\", \"browser\"]  # Avoid \"device_id\"\n",
    "\n",
    "# Features to Label Encode (high-cardinality ones)\n",
    "high_cardinality_features = [\"device_id\", \"country\"]\n",
    "\n",
    "# One-Hot Encode only low-cardinality categorical variables\n",
    "df_fraud = pd.get_dummies(df_fraud, columns=low_cardinality_features, drop_first=True)\n",
    "\n",
    "# Label Encode high-cardinality features\n",
    "label_encoder = LabelEncoder()\n",
    "for feature in high_cardinality_features:\n",
    "    if feature in df_fraud.columns:\n",
    "        df_fraud[feature] = label_encoder.fit_transform(df_fraud[feature])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Splitting the data into Features and Targets\n",
    "X = df_fraud.drop(columns='class',  axis=1)\n",
    "Y = df_fraud['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the column is in datetime format\n",
    "X['signup_time'] = pd.to_datetime(X['signup_time'])\n",
    "\n",
    "# Convert to Unix timestamp (seconds since epoch)\n",
    "X['signup_time'] = X['signup_time'].astype('int64') // 10**9\n",
    "\n",
    "\n",
    "# Ensure the column is in datetime format\n",
    "X['purchase_time'] = pd.to_datetime(X['purchase_time'])\n",
    "\n",
    "\n",
    "# Convert to Unix timestamp (seconds since epoch)\n",
    "X['purchase_time'] = X['purchase_time'].astype('int64') // 10**9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['year'] = pd.to_datetime(X['purchase_time']).dt.year\n",
    "X['month'] = pd.to_datetime(X['purchase_time']).dt.month\n",
    "X['day'] = pd.to_datetime(X['purchase_time']).dt.day\n",
    "X['hour'] = pd.to_datetime(X['purchase_time']).dt.hour\n",
    "\n",
    "\n",
    "X['year'] = pd.to_datetime(X['signup_time']).dt.year\n",
    "X['month'] = pd.to_datetime(X['signup_time']).dt.month\n",
    "X['day'] = pd.to_datetime(X['signup_time']).dt.day\n",
    "X['hour'] = pd.to_datetime(X['signup_time']).dt.hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "X,Y = SMOTE().fit_resample(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    116878\n",
       "1    116878\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'signup_time', 'purchase_time', 'purchase_value',\n",
      "       'device_id', 'age', 'ip_address', 'country', 'source_Direct',\n",
      "       'source_SEO', 'sex_M', 'browser_FireFox', 'browser_IE', 'browser_Opera',\n",
      "       'browser_Safari', 'year', 'month', 'day', 'hour'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Split the data into Traning data and Testing Data\n",
    "\n",
    "#X_train, X_test, Y_train,Y_test = train_test_split(X,Y, test_size=0.2, stratify=Y, random_state=2)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        user_id  signup_time  purchase_time  purchase_value  device_id  \\\n",
      "102270   399273   1429493192     1434826571        2.733284      36597   \n",
      "132404   357781   1420161439     1420161440       -0.214680      55858   \n",
      "178920   308412   1420277194     1420277195        0.877158      25367   \n",
      "509      285346   1434390032     1441721181        0.331239     115966   \n",
      "10998    152842   1431101933     1441383337        2.405732      16413   \n",
      "...         ...          ...            ...             ...        ...   \n",
      "34253     29555   1421098277     1421098278       -0.815192      72468   \n",
      "223744   266367   1420486720     1420486721       -0.487640      57172   \n",
      "27014    359925   1431070420     1438294864        0.440423      26134   \n",
      "79011     72788   1427780104     1432592675        0.276647     114723   \n",
      "47333    294668   1428216672     1430313801        0.331239      44780   \n",
      "\n",
      "             age  ip_address  country  source_Direct  source_SEO  sex_M  \\\n",
      "102270 -1.523855  2993528034      170          False       False  False   \n",
      "132404 -0.711344  3305555599      164          False        True   True   \n",
      "178920  1.029752  1842040972       98          False        True   True   \n",
      "509    -0.363124    30315818       36          False       False   True   \n",
      "10998   1.029752   340099854      171          False        True   True   \n",
      "...          ...         ...      ...            ...         ...    ...   \n",
      "34253  -0.363124  1028433935       88          False        True  False   \n",
      "223744 -1.523855  1165729258      171          False        True   True   \n",
      "27014   0.449387   796155817       32          False       False  False   \n",
      "79011   0.101168  2311323199      170          False       False   True   \n",
      "47333   1.958337  1386819572      118          False       False   True   \n",
      "\n",
      "        browser_FireFox  browser_IE  browser_Opera  browser_Safari  year  \\\n",
      "102270             True       False          False           False  1970   \n",
      "132404            False       False           True           False  1970   \n",
      "178920            False       False          False           False  1970   \n",
      "509               False       False          False            True  1970   \n",
      "10998             False       False          False           False  1970   \n",
      "...                 ...         ...            ...             ...   ...   \n",
      "34253             False       False          False            True  1970   \n",
      "223744             True       False          False           False  1970   \n",
      "27014             False       False          False           False  1970   \n",
      "79011             False       False           True           False  1970   \n",
      "47333             False        True          False           False  1970   \n",
      "\n",
      "        month  day  hour  \n",
      "102270      1    1     0  \n",
      "132404      1    1     0  \n",
      "178920      1    1     0  \n",
      "509         1    1     0  \n",
      "10998       1    1     0  \n",
      "...       ...  ...   ...  \n",
      "34253       1    1     0  \n",
      "223744      1    1     0  \n",
      "27014       1    1     0  \n",
      "79011       1    1     0  \n",
      "47333       1    1     0  \n",
      "\n",
      "[187004 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "print (X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.65      0.66     23376\n",
      "           1       0.66      0.69      0.68     23376\n",
      "\n",
      "    accuracy                           0.67     46752\n",
      "   macro avg       0.67      0.67      0.67     46752\n",
      "weighted avg       0.67      0.67      0.67     46752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the model parameters \n",
    "params = {\n",
    "    'solver': 'lbfgs',\n",
    "    'max_iter': 1000,\n",
    "    'multi_class': 'auto',\n",
    "    'random_state': 8888,\n",
    "}\n",
    "\n",
    "#Train the model \n",
    "lr = LogisticRegression(**params)\n",
    "lr.fit(X_train, Y_train)\n",
    "\n",
    "#predict on the test set \n",
    "Y_pred = lr.predict(X_test)\n",
    "\n",
    "report = classification_report(Y_test,Y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.6792063207038965,\n",
       "  'recall': 0.6472450376454483,\n",
       "  'f1-score': 0.6628406203452204,\n",
       "  'support': 23376.0},\n",
       " '1': {'precision': 0.6630985455139728,\n",
       "  'recall': 0.6943018480492813,\n",
       "  'f1-score': 0.6783415531221265,\n",
       "  'support': 23376.0},\n",
       " 'accuracy': 0.6707734428473648,\n",
       " 'macro avg': {'precision': 0.6711524331089347,\n",
       "  'recall': 0.6707734428473648,\n",
       "  'f1-score': 0.6705910867336735,\n",
       "  'support': 46752.0},\n",
       " 'weighted avg': {'precision': 0.6711524331089347,\n",
       "  'recall': 0.6707734428473648,\n",
       "  'f1-score': 0.6705910867336734,\n",
       "  'support': 46752.0}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_dict = classification_report(Y_test, Y_pred, output_dict=True)\n",
    "report_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 1: Train Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.65      0.66     23376\n",
      "           1       0.66      0.69      0.68     23376\n",
      "\n",
      "    accuracy                           0.67     46752\n",
      "   macro avg       0.67      0.67      0.67     46752\n",
      "weighted avg       0.67      0.67      0.67     46752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(C=1, solver='liblinear')\n",
    "log_reg.fit(X_train,Y_train)\n",
    "Y_pred_log_reg = log_reg.predict(X_test)\n",
    "print(classification_report(Y_test,Y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 2: Train Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.65      0.66     23376\n",
      "           1       0.66      0.69      0.68     23376\n",
      "\n",
      "    accuracy                           0.67     46752\n",
      "   macro avg       0.67      0.67      0.67     46752\n",
      "weighted avg       0.67      0.67      0.67     46752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=30, max_depth=3)\n",
    "rf_clf.fit(X_train,Y_train)\n",
    "Y_pred_rf = rf_clf.predict(X_test)\n",
    "print(classification_report(Y_test,Y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 3: Train XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.65      0.66     23376\n",
      "           1       0.66      0.69      0.68     23376\n",
      "\n",
      "    accuracy                           0.67     46752\n",
      "   macro avg       0.67      0.67      0.67     46752\n",
      "weighted avg       0.67      0.67      0.67     46752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(use_lable_encoder=False, eval_metric='logloss')\n",
    "xgb_clf.fit(X_train,Y_train)\n",
    "Y_pred_xgb = xgb_clf.predict(X_test)\n",
    "print(classification_report(Y_test,Y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 4: Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.92      0.83     23376\n",
      "           1       0.90      0.71      0.79     23376\n",
      "\n",
      "    accuracy                           0.82     46752\n",
      "   macro avg       0.83      0.82      0.81     46752\n",
      "weighted avg       0.83      0.82      0.81     46752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(max_depth=5)  # You can tune hyperparameters\n",
    "dt_clf.fit(X_train, Y_train)\n",
    "Y_pred_dt = dt_clf.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test, Y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X , Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fraud_data_model.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(dtc, 'fraud_data_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('fraud_data_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Track ML models Experiments Using MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\n",
    "        'Logistic Regression',\n",
    "        LogisticRegression(C=1, solver='liblinear'),\n",
    "        (X_train,Y_train),\n",
    "        (X_test,Y_test)\n",
    "\n",
    "    ),\n",
    "    (\n",
    "        'Random Forest',\n",
    "        RandomForestClassifier(n_estimators=30, max_depth=3),\n",
    "        (X_train,Y_train),\n",
    "        (X_test,Y_test)\n",
    "    ),\n",
    "    (\n",
    "         'XGBClassifier',\n",
    "          XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "          (X_train,Y_train),\n",
    "          (X_test,Y_test)\n",
    "    ),\n",
    "    (\n",
    "        'Decision Tree',\n",
    "         DecisionTreeClassifier(max_depth=5),\n",
    "        (X_train,Y_train),\n",
    "        (X_test,Y_test)\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = []\n",
    "\n",
    "for model_name, model, train_set, test_set in models:\n",
    "    X_train = train_set[0]\n",
    "    Y_train = train_set[1]\n",
    "    X_test = test_set[0]\n",
    "    Y_test = test_set[1]\n",
    "\n",
    "    model.fit(X_train, Y_train)\n",
    "    Y_pred = model.predict(X_test)\n",
    "    report = classification_report(Y_test, Y_pred,output_dict=True)\n",
    "    reports.append(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/16 12:50:47 INFO mlflow.tracking.fluent: Experiment with name 'model tranning for fraud_data' does not exist. Creating a new experiment.\n",
      "2025/02/16 12:51:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Logistic Regression at: http://127.0.0.1:5000/#/experiments/200134848443818606/runs/1518b25792294a828563c90c9825081e\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/200134848443818606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/16 12:51:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Random Forest at: http://127.0.0.1:5000/#/experiments/200134848443818606/runs/ddd42c9e63914393b2906b644fab5a36\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/200134848443818606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/16 12:51:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run XGBClassifier at: http://127.0.0.1:5000/#/experiments/200134848443818606/runs/8b6e960e80a14b6c8bb85379aaa42f06\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/200134848443818606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/16 12:52:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Decision Tree at: http://127.0.0.1:5000/#/experiments/200134848443818606/runs/fcbd5cafdd2c49e5a11d96aec7b30729\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/200134848443818606\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment('model tranning for fraud_data')\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")\n",
    "\n",
    "for i, element in enumerate(models):\n",
    "    model_name = element[0]\n",
    "    model = element[1]\n",
    "    report = reports[i]\n",
    "\n",
    "    with mlflow.start_run(run_name = model_name):\n",
    "        mlflow.log_param('model_name', model_name)\n",
    "        mlflow.log_metric('accuracy', report['accuracy'])\n",
    "        mlflow.log_metric('recall_class_1', report['1']['recall'])\n",
    "        mlflow.log_metric('recall_class_0', report['0']['recall'])\n",
    "        mlflow.log_metric('f1_score_macro', report['macro avg']['f1-score'])\n",
    "\n",
    "        if 'XGB' in model_name:\n",
    "            mlflow.xgboost.log_model(model, 'model')\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(model, 'model')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train  Deep learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 1:Multi-Layer Perceptron (MLP) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     23376\n",
      "           1       0.50      1.00      0.67     23376\n",
      "\n",
      "    accuracy                           0.50     46752\n",
      "   macro avg       0.25      0.50      0.33     46752\n",
      "weighted avg       0.25      0.50      0.33     46752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)\n",
    "mlp_clf.fit(X_train, Y_train)\n",
    "Y_pred_mlp = mlp_clf.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test, Y_pred_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 2 : Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 8ms/step - accuracy: 0.8289 - loss: 1866403.0000\n",
      "Epoch 2/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 9ms/step - accuracy: 0.8253 - loss: 456893.4375\n",
      "Epoch 3/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 10ms/step - accuracy: 0.8303 - loss: 219493.8906\n",
      "Epoch 4/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 11ms/step - accuracy: 0.8249 - loss: 114394.9766\n",
      "Epoch 5/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 10ms/step - accuracy: 0.8478 - loss: 33536.3516\n",
      "Epoch 6/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 11ms/step - accuracy: 0.8979 - loss: 10.8453\n",
      "Epoch 7/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 9ms/step - accuracy: 0.9051 - loss: 0.3283\n",
      "Epoch 8/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 10ms/step - accuracy: 0.9058 - loss: 0.3121\n",
      "Epoch 9/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 11ms/step - accuracy: 0.9044 - loss: 0.3154\n",
      "Epoch 10/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 10ms/step - accuracy: 0.9053 - loss: 0.3132\n",
      "\u001b[1m808/808\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95     23376\n",
      "           1       0.00      0.00      0.00      2454\n",
      "\n",
      "    accuracy                           0.90     25830\n",
      "   macro avg       0.45      0.50      0.48     25830\n",
      "weighted avg       0.82      0.90      0.86     25830\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "# Convert DataFrame to NumPy array\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "# Reshape input for CNN\n",
    "X_train_cnn = X_train.reshape(-1, X_train.shape[1], 1)\n",
    "X_test_cnn = X_test.reshape(-1, X_test.shape[1], 1)\n",
    "\n",
    "X_train_cnn = X_train_cnn.astype(np.float32)\n",
    "X_test_cnn = X_test_cnn.astype(np.float32)\n",
    "\n",
    "\n",
    "# Check if it's binary or multi-class\n",
    "num_classes = len(np.unique(Y_train))\n",
    "\n",
    "if num_classes == 2:\n",
    "    # Binary classification (0/1)\n",
    "    Y_train_cnn = np.array(Y_train)\n",
    "    Y_test_cnn = np.array(Y_test)\n",
    "    loss_function = \"binary_crossentropy\"\n",
    "    final_activation = \"sigmoid\"\n",
    "    output_units = 1\n",
    "else:\n",
    "    # Multi-class classification\n",
    "    Y_train_cnn = to_categorical(Y_train, num_classes)\n",
    "    Y_test_cnn = to_categorical(Y_test, num_classes)\n",
    "    loss_function = \"categorical_crossentropy\"\n",
    "    final_activation = \"softmax\"\n",
    "    output_units = num_classes\n",
    "\n",
    "# Define CNN model\n",
    "cnn_model = models.Sequential([\n",
    "    layers.Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(50, activation='relu'),\n",
    "    layers.Dense(output_units, activation=final_activation)  # Adjust for binary/multi-class\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss=loss_function, metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "cnn_model.fit(X_train_cnn, Y_train_cnn, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "# Predictions\n",
    "Y_pred_cnn = cnn_model.predict(X_test_cnn)\n",
    "Y_pred_cnn_classes = (Y_pred_cnn > 0.5).astype(int) if num_classes == 2 else Y_pred_cnn.argmax(axis=1)\n",
    "\n",
    "print(classification_report(Y_test, Y_pred_cnn_classes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 7:Recurrent Neural Network (RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.8302 - loss: 32598.8457\n",
      "Epoch 2/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 11ms/step - accuracy: 0.8362 - loss: 73.9595\n",
      "Epoch 3/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 11ms/step - accuracy: 0.8160 - loss: 30.7390\n",
      "Epoch 4/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 11ms/step - accuracy: 0.8364 - loss: 2.0003\n",
      "Epoch 5/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 11ms/step - accuracy: 0.8851 - loss: 5.1223\n",
      "Epoch 6/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 11ms/step - accuracy: 0.8389 - loss: 2.8985\n",
      "Epoch 7/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 10ms/step - accuracy: 0.8652 - loss: 0.7916\n",
      "Epoch 8/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 10ms/step - accuracy: 0.9032 - loss: 0.3504\n",
      "Epoch 9/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 10ms/step - accuracy: 0.9056 - loss: 0.3198\n",
      "Epoch 10/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 10ms/step - accuracy: 0.9031 - loss: 0.5513\n",
      "\u001b[1m808/808\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95     23376\n",
      "           1       0.00      0.00      0.00      2454\n",
      "\n",
      "    accuracy                           0.90     25830\n",
      "   macro avg       0.45      0.50      0.48     25830\n",
      "weighted avg       0.82      0.90      0.86     25830\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import SimpleRNN\n",
    "\n",
    "# # Convert DataFrame to NumPy array\n",
    "\n",
    "X_train = np.array(X_train, dtype=np.float32)\n",
    "X_test = np.array(X_test, dtype=np.float32)\n",
    "\n",
    "Y_train = np.array(Y_train, dtype=np.int32)\n",
    "Y_test = np.array(Y_test, dtype=np.int32)\n",
    "\n",
    "\n",
    "rnn_model = models.Sequential([\n",
    "    SimpleRNN(50, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    layers.Dense(50, activation='relu'),\n",
    "    layers.Dense(output_units, activation=final_activation)  # Adjusted for binary/multi-class\n",
    "])\n",
    "\n",
    "rnn_model.compile(optimizer='adam', loss=loss_function, metrics=['accuracy'])\n",
    "\n",
    "rnn_model.fit(X_train, Y_train, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "Y_pred_rnn = rnn_model.predict(X_test)\n",
    "Y_pred_rnn_classes = (Y_pred_rnn > 0.5).astype(int) if num_classes == 2 else Y_pred_rnn.argmax(axis=1)\n",
    "\n",
    "print(classification_report(Y_test, Y_pred_rnn_classes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 8:Long Short-Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 16ms/step - accuracy: 0.8010 - loss: 432141.8438\n",
      "Epoch 2/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 18ms/step - accuracy: 0.8280 - loss: 57401.3125\n",
      "Epoch 3/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 17ms/step - accuracy: 0.8267 - loss: 57181.1602\n",
      "Epoch 4/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 16ms/step - accuracy: 0.8267 - loss: 41752.3047\n",
      "Epoch 5/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 16ms/step - accuracy: 0.8520 - loss: 2774.8015\n",
      "Epoch 6/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 16ms/step - accuracy: 0.9053 - loss: 0.3135\n",
      "Epoch 7/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 16ms/step - accuracy: 0.9050 - loss: 0.3142\n",
      "Epoch 8/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 16ms/step - accuracy: 0.9031 - loss: 0.3187\n",
      "Epoch 9/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 16ms/step - accuracy: 0.9024 - loss: 9.1530\n",
      "Epoch 10/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 17ms/step - accuracy: 0.9046 - loss: 0.3232\n",
      "\u001b[1m808/808\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95     23376\n",
      "           1       0.00      0.00      0.00      2454\n",
      "\n",
      "    accuracy                           0.90     25830\n",
      "   macro avg       0.45      0.50      0.48     25830\n",
      "weighted avg       0.82      0.90      0.86     25830\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# # Convert DataFrame to NumPy array\n",
    "\n",
    "X_train = np.array(X_train, dtype=np.float32)\n",
    "X_test = np.array(X_test, dtype=np.float32)\n",
    "\n",
    "Y_train = np.array(Y_train, dtype=np.int32)\n",
    "Y_test = np.array(Y_test, dtype=np.int32)\n",
    "\n",
    "lstm_model = models.Sequential([\n",
    "    LSTM(50, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    layers.Dense(50, activation='relu'),\n",
    "    layers.Dense(output_units, activation=final_activation)  # Adjusted for binary/multi-class\n",
    "])\n",
    "\n",
    "lstm_model.compile(optimizer='adam', loss=loss_function, metrics=['accuracy'])\n",
    "\n",
    "lstm_model.fit(X_train_cnn, Y_train_cnn, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "Y_pred_lstm = lstm_model.predict(X_test_cnn)\n",
    "Y_pred_lstm_classes = (Y_pred_lstm > 0.5).astype(int) if num_classes == 2 else Y_pred_lstm.argmax(axis=1)\n",
    "\n",
    "print(classification_report(Y_test, Y_pred_lstm_classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Track Deep learning models Experiments Using MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_learning_models = {\n",
    "    \"CNN\": models.Sequential([\n",
    "        layers.Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(50, activation='relu'),\n",
    "        layers.Dense(output_units, activation=final_activation)\n",
    "    ]),\n",
    "    \"RNN\": models.Sequential([\n",
    "        layers.SimpleRNN(50, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "        layers.Dense(50, activation='relu'),\n",
    "        layers.Dense(output_units, activation=final_activation)\n",
    "    ]),\n",
    "    \"LSTM\": models.Sequential([\n",
    "        layers.LSTM(50, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "        layers.Dense(50, activation='relu'),\n",
    "        layers.Dense(output_units, activation=final_activation)\n",
    "    ])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment('model tranning for fraud_data')\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.8305 - loss: 2024370.8750\n",
      "Epoch 2/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 12ms/step - accuracy: 0.8273 - loss: 682612.3750\n",
      "Epoch 3/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 13ms/step - accuracy: 0.8284 - loss: 303261.2812\n",
      "Epoch 4/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 10ms/step - accuracy: 0.8286 - loss: 103756.9219\n",
      "Epoch 5/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 10ms/step - accuracy: 0.8279 - loss: 38138.3555\n",
      "Epoch 6/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 11ms/step - accuracy: 0.9026 - loss: 131.0138\n",
      "Epoch 7/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 10ms/step - accuracy: 0.9042 - loss: 0.3159\n",
      "Epoch 8/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 10ms/step - accuracy: 0.9064 - loss: 0.3107\n",
      "Epoch 9/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 10ms/step - accuracy: 0.9044 - loss: 0.3153\n",
      "Epoch 10/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 10ms/step - accuracy: 0.9038 - loss: 0.3166\n",
      "\u001b[1m808/808\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/16 13:35:59 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "2025/02/16 13:36:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged CNN successfully in MLflow\n",
      "üèÉ View run CNN at: http://127.0.0.1:5000/#/experiments/200134848443818606/runs/e67592a1c7884b2faf5fd08d8aeecfe8\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/200134848443818606\n",
      "Epoch 1/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 9ms/step - accuracy: 0.8188 - loss: 12467.9385\n",
      "Epoch 2/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 10ms/step - accuracy: 0.8257 - loss: 198.6428\n",
      "Epoch 3/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 10ms/step - accuracy: 0.8310 - loss: 24.4148\n",
      "Epoch 4/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 11ms/step - accuracy: 0.8458 - loss: 1.6816\n",
      "Epoch 5/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 11ms/step - accuracy: 0.8943 - loss: 0.9636\n",
      "Epoch 6/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 12ms/step - accuracy: 0.8950 - loss: 0.4410\n",
      "Epoch 7/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 12ms/step - accuracy: 0.8999 - loss: 0.5920\n",
      "Epoch 8/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 11ms/step - accuracy: 0.9040 - loss: 0.3399\n",
      "Epoch 9/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 11ms/step - accuracy: 0.9049 - loss: 0.3183\n",
      "Epoch 10/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 11ms/step - accuracy: 0.9041 - loss: 0.3204\n",
      "\u001b[1m808/808\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/16 13:42:29 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "2025/02/16 13:43:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged RNN successfully in MLflow\n",
      "üèÉ View run RNN at: http://127.0.0.1:5000/#/experiments/200134848443818606/runs/7ca7d1eeddec4daaab4acec65ae98c27\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/200134848443818606\n",
      "Epoch 1/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.7937 - loss: 391872.7500\n",
      "Epoch 2/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 8ms/step - accuracy: 0.8307 - loss: 24.4156\n",
      "Epoch 3/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 8ms/step - accuracy: 0.8593 - loss: 13515.5186\n",
      "Epoch 4/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 8ms/step - accuracy: 0.8311 - loss: 907.5781\n",
      "Epoch 5/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 8ms/step - accuracy: 0.8525 - loss: 148.7984\n",
      "Epoch 6/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 8ms/step - accuracy: 0.8813 - loss: 851.8013\n",
      "Epoch 7/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 8ms/step - accuracy: 0.9023 - loss: 0.6637\n",
      "Epoch 8/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 8ms/step - accuracy: 0.9047 - loss: 0.3148\n",
      "Epoch 9/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.9040 - loss: 1.0732\n",
      "Epoch 10/10\n",
      "\u001b[1m3229/3229\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 8ms/step - accuracy: 0.9053 - loss: 0.3134\n",
      "\u001b[1m808/808\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/16 13:47:21 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "2025/02/16 13:47:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged LSTM successfully in MLflow\n",
      "üèÉ View run LSTM at: http://127.0.0.1:5000/#/experiments/200134848443818606/runs/2ba9f4ce4379409f9fcb9686a2e6e11c\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/200134848443818606\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in deep_learning_models.items():\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Compile and Train\n",
    "        model.compile(optimizer='adam', loss=loss_function, metrics=['accuracy'])\n",
    "        model.fit(X_train_cnn, Y_train_cnn, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "        # Make predictions\n",
    "        Y_pred = model.predict(X_test_cnn)\n",
    "        Y_pred_classes = (Y_pred > 0.5).astype(int) if num_classes == 2 else Y_pred.argmax(axis=1)\n",
    "\n",
    "        # Compute classification metrics\n",
    "        report = classification_report(Y_test, Y_pred_classes, output_dict=True)\n",
    "\n",
    "        # Log metrics\n",
    "        mlflow.log_metrics({\n",
    "            'accuracy': report['accuracy'],\n",
    "            'recall_class_0': report['0']['recall'],\n",
    "            'recall_class_1': report['1']['recall'],\n",
    "            'f1_score_macro': report['macro avg']['f1-score']\n",
    "        })\n",
    "\n",
    "        # Log deep learning model\n",
    "        mlflow.tensorflow.log_model(model, model_name)\n",
    "\n",
    "        print(f\"Logged {model_name} successfully in MLflow\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
